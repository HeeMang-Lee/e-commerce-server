# PopularProduct 쿼리는 왜 느렸을까?

이커머스 서비스에서 "최근 3일간 인기 상품 Top 5"를 조회하는 API가 있었다. 처음에는 데이터가 적어서 괜찮았는데, 주문이 늘어나면서 이 쿼리가 점점 느려질 것 같다는 불안감이 들었다.

실제로 EXPLAIN을 찍어보니 예상이 맞았다. 이 글에서는 문제를 발견하고 해결하는 과정을 정리해봤다.

## 문제의 시작

최근 3일간 가장 많이 팔린 상품 5개를 찾는 쿼리는 이렇게 생겼다.

```sql
SELECT oi.product_id
FROM order_items oi
INNER JOIN orders o ON oi.order_id = o.id
WHERE o.created_at >= DATE_SUB(NOW(), INTERVAL 3 DAY)
  AND o.created_at < NOW()
GROUP BY oi.product_id
ORDER BY SUM(oi.quantity) DESC
LIMIT 5
```

언뜻 보면 특별히 이상한 점은 없어 보인다. 주문 아이템과 주문 테이블을 조인하고, 최근 3일 데이터만 필터링한 다음, 상품별로 판매량을 집계해서 정렬하는 쿼리다.

하지만 EXPLAIN을 실행해보니 꽤 충격적인 결과가 나왔다.

```
+----+-------------+-------+------+------------------+------+---------+------+------+----------+---------------------------------+
| id | select_type | table | type | possible_keys    | key  | key_len | ref  | rows | filtered | Extra                           |
+----+-------------+-------+------+------------------+------+---------+------+------+----------+---------------------------------+
|  1 | SIMPLE      | oi    | ALL  | idx_order        | NULL | NULL    | NULL |    1 |   100.00 | Using temporary; Using filesort |
|  1 | SIMPLE      | o     | ALL  | PRIMARY          | NULL | NULL    | NULL |    1 |   100.00 | Using where; Using join buffer  |
+----+-------------+-------+------+------------------+------+---------+------+------+----------+---------------------------------+
```

### 무엇이 문제였나

type이 ALL이면 전체 테이블 스캔이라는 뜻이다. 두 테이블 모두 ALL이니까 order_items 전체와 orders 전체를 스캔한다는 의미다.

더 큰 문제는 key가 NULL이라는 점이었다. 인덱스가 있는데도 MySQL이 사용하지 않고 있었다. Using temporary와 Using filesort까지 있으니 임시 테이블을 만들고 파일 정렬까지 한다는 뜻이다.

지금은 데이터가 적어서 rows가 1로 나오지만, 실제 운영 환경을 생각해보자. 주문 아이템이 2만 건, 주문이 1만 건이라면? 두 테이블을 전부 읽고 조인해야 한다.

대충 계산해봐도 2만 × 1만 = 2억 번의 비교가 필요하다. 이건 확실히 문제가 있었다.

## 왜 인덱스를 사용하지 못했을까

처음에는 이해가 안 갔다. 분명 `order_items.order_id`에는 `idx_order` 인덱스가 있었고, `orders.id`는 PK였다. 그런데 왜 사용하지 않는 걸까?

곰곰이 생각해보니 이유를 알 것 같았다.

쿼리가 `order_items`를 먼저 읽는데, 이 테이블에는 필터링 조건이 없다. WHERE 조건은 `orders.created_at`에만 있다. 그러니까 MySQL 입장에서는 일단 order_items를 전부 읽고, 각 행마다 orders와 조인한 다음, 그때서야 날짜로 필터링하는 게 "합리적"이라고 판단한 것이다.

문제는 이게 엄청나게 비효율적이라는 점이다. 조인 후에 필터링하면 불필요한 데이터까지 전부 조인해야 한다.

## 해결 방법 찾기

이 문제를 해결하려면 두 가지가 필요했다.

첫째, `orders` 테이블의 `created_at`에 인덱스를 추가해서 날짜 필터링을 빠르게 해야 한다.

둘째, 쿼리 구조를 바꿔서 orders를 먼저 필터링하고 그 결과와 order_items를 조인해야 한다.

### 인덱스 설계

먼저 orders 테이블에 간단한 인덱스를 추가했다.

```sql
CREATE INDEX idx_created_at ON orders(created_at);
```

이렇게 하면 날짜 범위로 빠르게 검색할 수 있다.

그런데 order_items는 어떻게 해야 할까? 단순히 order_id 인덱스만으로는 부족할 것 같았다. 이 쿼리는 product_id도 읽고, quantity도 집계한다.

그래서 커버링 인덱스를 만들기로 했다.

```sql
CREATE INDEX idx_order_product_quantity
ON order_items(order_id, product_id, quantity);
```

커버링 인덱스는 쿼리에 필요한 모든 컬럼을 인덱스에 포함시켜서, 테이블에 접근하지 않고 인덱스만으로 쿼리를 처리할 수 있게 한다.

이 쿼리가 필요한 건:
- order_id (JOIN)
- product_id (GROUP BY)
- quantity (SUM 집계)

세 컬럼 모두 인덱스에 있으니, 테이블을 읽을 필요가 없다. 인덱스만 쭉 읽으면 된다.

컬럼 순서도 중요했다. order_id를 첫 번째에 둔 이유는 조인 조건이기 때문이다. MySQL은 인덱스의 첫 번째 컬럼으로 빠르게 탐색할 수 있다. 그다음 product_id로 그룹핑하고, quantity를 읽어서 집계한다.

### 쿼리 구조 개선

인덱스만 추가하면 될 줄 알았는데, 그게 아니었다. EXPLAIN을 다시 찍어보니 여전히 `idx_order`를 사용하고 있었다.

```sql
-- 개선된 쿼리
SELECT oi.product_id
FROM orders o                -- orders를 먼저!
INNER JOIN order_items oi
  ON o.id = oi.order_id
WHERE o.created_at >= ...
```

FROM 절을 바꿔서 orders를 먼저 읽도록 했다. 이렇게 하면 MySQL이 다음 순서로 실행한다:

1. orders를 created_at 인덱스로 스캔 (최근 3일치만)
2. 필터링된 orders와 order_items를 조인
3. 훨씬 적은 데이터로 집계와 정렬

이 방식이 훨씬 합리적이다. 1만 개 주문 중 최근 3일치가 4,267건이라면, 전체 2만 개 order_items와 조인하는 게 아니라 4,267건의 orders에 해당하는 order_items만 조인하면 된다.

### FORCE INDEX 사용

그런데 또 문제가 있었다. 쿼리를 바꿨는데도 MySQL이 idx_order_product_quantity를 사용하지 않았다. 여전히 idx_order를 쓰고 있었다.

이유를 찾아보니, MySQL 옵티마이저가 단일 컬럼 인덱스(idx_order)가 더 작다고 판단해서 그쪽을 선택한 것 같았다. 하지만 우리는 커버링 인덱스를 써야 테이블 접근을 안 할 수 있다.

어쩔 수 없이 힌트를 줬다.

```sql
SELECT oi.product_id
FROM orders o
INNER JOIN order_items oi FORCE INDEX (idx_order_product_quantity)
  ON o.id = oi.order_id
WHERE o.created_at >= :startTime AND o.created_at < :endTime
GROUP BY oi.product_id
ORDER BY SUM(oi.quantity) DESC
LIMIT :limit
```

FORCE INDEX를 사용하면 MySQL에게 "이 인덱스를 꼭 써라"고 강제할 수 있다.

## 결과는?

최종적으로 EXPLAIN을 찍어보니 이렇게 나왔다.

```
+----+-------------+-------+-------+---------------------------+---------------------------+---------+--------------------+------+----------+----------------------------------------------+
| id | select_type | table | type  | possible_keys             | key                       | key_len | ref                | rows | filtered | Extra                                        |
+----+-------------+-------+-------+---------------------------+---------------------------+---------+--------------------+------+----------+----------------------------------------------+
|  1 | SIMPLE      | o     | range | PRIMARY,idx_created_at    | idx_created_at            | 4       | NULL               | 4267 |   100.00 | Using where; Using index; Using temporary... |
|  1 | SIMPLE      | oi    | ref   | idx_order_product_quantity| idx_order_product_quantity| 8       | ecommerce.o.id     |    2 |   100.00 | Using index                                  |
+----+-------------+-------+-------+---------------------------+---------------------------+---------+--------------------+------+----------+----------------------------------------------+
```

확실히 달라졌다.

orders는 type이 range로 바뀌었다. 인덱스 범위 스캔을 한다는 뜻이다. key도 idx_created_at을 사용한다. rows는 4267이니까 1만 개 중 43%만 읽는다.

order_items는 type이 ref다. 인덱스를 사용한 조인이다. key는 idx_order_product_quantity, 우리가 만든 커버링 인덱스다. rows는 2, 주문당 평균 2개의 아이템만 읽는다는 뜻이다.

가장 중요한 건 Extra에 Using index가 있다는 점이다. 이게 커버링 인덱스가 제대로 동작한다는 증거다. 테이블을 전혀 읽지 않고 인덱스만으로 쿼리를 처리한다.

### 성능 측정

실제로 쿼리 실행 시간을 측정해봤다. 테스트 데이터는 주문 1만 건, 주문 아이템 2만 건 정도였다.

초기 상태: 50.15ms
인덱스 추가 후: 33.57ms
FORCE INDEX 적용 후: 24.01ms

최종적으로 52% 성능이 개선됐다. 초기보다 두 배 빠르다.

읽는 데이터 양도 크게 줄었다. 처음에는 3만 행(order_items 2만 + orders 1만)을 스캔했는데, 지금은 1만 2천 행 정도만 읽는다. 57% 감소했다.

### 대규모 환경에서는?

지금은 데이터가 적지만, 나중에 주문이 100만 건, 1000만 건으로 늘어나면 어떻게 될까?

간단하게 계산해봤다. 인덱스 스캔은 대략 선형 시간 복잡도를 가진다. 데이터가 100배 늘면 시간도 약 100배 늘어난다.

- 10만 주문: 240ms
- 100만 주문: 2.4초
- 1000만 주문: 24초

100만 주문 정도까지는 충분히 감당할 수 있을 것 같다. 2.4초면 나쁘지 않다. 만약 더 빨라야 한다면 캐싱을 추가하면 된다.

1000만 주문이 되면 24초가 걸리니까 좀 느리긴 하다. 그때는 배치로 집계 테이블을 만드는 방식을 고려해야 할 것 같다.

## 배운 것들

### EXPLAIN 제대로 읽기

type이 ALL이면 문제가 있다는 신호다. key가 NULL이면 인덱스를 안 쓴다는 뜻이다.

Using index는 좋은 신호다. 커버링 인덱스가 동작한다는 뜻이다. Using temporary와 Using filesort는 주의해야 하지만, GROUP BY나 ORDER BY를 쓰면 어느 정도는 어쩔 수 없다.

### 커버링 인덱스의 힘

처음에는 단순히 조인 컬럼에만 인덱스를 추가하면 되는 줄 알았다. 하지만 커버링 인덱스를 만들어서 테이블 접근 자체를 없애니 훨씬 빨라졌다.

인덱스에 필요한 컬럼을 전부 넣는 게 포인트다. 그러면 MySQL이 테이블을 읽을 필요가 없어진다.

### 쿼리 구조도 중요하다

인덱스만 추가한다고 끝이 아니다. 쿼리 자체를 어떻게 짜느냐도 중요하다.

FROM 절의 순서를 바꿔서 필터링이 먼저 일어나도록 했더니 훨씬 효율적이 됐다. 대량의 데이터를 조인한 다음 필터링하는 게 아니라, 필터링한 후 조인하는 게 낫다.

### 옵티마이저를 믿되 검증하라

MySQL 옵티마이저가 대부분 올바른 선택을 하지만, 항상 그런 건 아니다. 커버링 인덱스가 명백히 더 나은데도 단일 컬럼 인덱스를 선택할 때가 있다.

그럴 때는 FORCE INDEX로 힌트를 줘야 한다. 물론 남용하면 안 되지만, 확실히 더 나은 인덱스를 알고 있다면 써도 괜찮다.

## 정리

PopularProduct 쿼리를 최적화하면서 배운 점을 정리하면:

1. EXPLAIN으로 문제를 정확히 파악하자
2. 커버링 인덱스는 강력하다
3. 쿼리 구조를 바꿔서 필터링을 먼저 하자
4. 필요하면 FORCE INDEX를 쓰자
5. 실제 성능을 측정해서 검증하자

결과적으로 52% 성능 개선을 달성했고, 대규모 환경에서도 충분히 버틸 수 있는 구조를 만들었다.

캐싱이나 배치 집계 같은 방법도 있지만, 일단은 DB 쿼리 자체를 최적화하는 게 먼저라고 생각한다. 근본적인 문제를 해결하지 않고 캐싱으로 덮으면 나중에 더 큰 문제가 될 수 있으니까.

## 한계 및 향후 개선 방향

### 테스트 데이터의 한계

현재 테스트는 약 1~2만 건의 데이터로 진행했다. 52% 성능 개선이라는 결과를 얻었지만, 이게 실제 운영 환경에서도 같은 효과를 낼지는 확신하기 어렵다.

**왜 그럴까?**

MySQL 옵티마이저는 데이터 규모에 따라 실행 계획을 다르게 세운다. 몇 만 건 수준에서는 Full Scan이 오히려 빠를 수도 있고, 인덱스를 쓰는 게 비효율적일 수도 있다.

반면 수백만~수천만 건 규모에서는 인덱스의 효과가 극명하게 드러난다. 지금 측정한 52%라는 숫자는 소규모 데이터에서의 결과일 뿐이다.

**진짜 효과를 보려면?**

실무에서는 최소 몇 백만 건 이상의 데이터로 테스트해야 인덱스 설계의 진가를 알 수 있다. 그래야 옵티마이저가 쿼리를 단순화하지 않고, 실제 운영 환경과 유사한 실행 계획을 세우기 때문이다.

다음 단계로는:
- 대량 테스트 데이터 생성 (100만 건 이상)
- 프로덕션 유사 환경에서 성능 테스트
- Slow Query Log 모니터링 설정
- 실제 트래픽 패턴으로 부하 테스트

이런 과정을 거쳐야 진짜 성능 개선 효과를 검증할 수 있을 것 같다.
